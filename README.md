# GPT2-125M-replication
Implementation of GPT-2 small model with 125M parameters along with changes in architecture such as Rotary position embeddings and grouped query attention.
